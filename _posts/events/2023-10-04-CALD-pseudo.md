---
title: "CALD-pseudo: Computational Approaches to Language Data Pseudonymization"
excerpt_separator: "<!--more-->"
categories:
  - events
tags:
  - outreach
  - blog
---

------


# CALD-pseudo workshop at [EACL 2024](https://2024.eacl.org/)

_a cross-disciplinary forum for advancing privacy protection of unstructured text data & data openness through **pseudonymization**._

------

**Venue**: Hotel Radisson Blu, St. Julians, in Malta [link](https://2024.eacl.org/venue)

**Date**: Malta, March 21 or 22, 2024

**Registration**: coming soon

<!-- # Registration -->

<!-- # Program -->

------

## Workshop Topic and Content
Accessibility of research data is critical for advances in many research fields but textual data often cannot be shared due to the personal and sensitive information which it contains, e.g names, political opinions, sensitive personal information and medical data. General Data Protection Regulation, GDPR (EU Commission, 2016), suggests pseudonymization as a solution to secure open access to research data but we need to learn more about pseudonymization as an approach before adopting it for manipulation of research data (Volodina et al., 2023). The main challenge is how to effectively pseudonymize data so that such individuals cannot be identified but at the same time the data is still usable for the natural language processing tasks for which it was collected and for other types of research.
This workshop invites a broad community of researchers in all concerned cross-disciplinary fields to jointly discuss challenges within pseudonymization, such as

* automatic approaches to _detection and labelling_ of personal information in unstructured language data, including events and other context-dependent cues revealing a person;
* developing context-sensitive algorithms for _replacement_ of personal information in unstructured data;
* studies into the _effects_ of pseudonymization on unstructured data, e.g. applicability of pseudonymised data for the intended research questions, readability of pseudonymised data or addition of unwelcome biases through pseudonymization;
* _effectiveness_ of pseudonymization as a way of protecting writer identity;
* _reidentification_ studies;
* constructing datasets for automatic pseudonymization, including _methodological and ethical aspects_ of those;
* approaches to the _evaluation_ of automatic pseudonymization both in concealing the private information and preserving the semantics of the non-personal data;
* and numerous other open questions.

------

## Submission information

We will be using the [ACL templates](https://github.com/acl-org/acl-style-files) for the workshop (you will find LaTeX and Word templates here). Please, make sure that your submissions take into consideration the following [ACLPUB instructions](https://acl-org.github.io/ACLPUB/formatting.html#style-files). Submissions that do not adhere to the ACLPUB guidelines will be rejected without review.

<!-- 
**IMPORTANT**: For licensing reasons, all camera-ready papers must include the following sentence as an unmarked (unnumbered) footnote on the first page of the paper: This work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: http://creativecommons.org/licenses/by/4.0/. NEW: Please note that the footnote will automatically be added to the final version for the LaTeX template (and Overleaf template once approved).

The footnote can be added by adding the following piece of code before the abstract: $\let\thefootnote\relax\footnotetext{This work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: http://creativecommons.org/licenses/by/4.0/.} $
-->

Authors are invited to submit _long papers_ (8-12 pages) alternatively _short_ or _demo_ papers (4-7 pages), page count not including references. Please indicate one relevant paper type at submission time. Only pdf files will be accepted. Submissions will be managed through the electronic conference management system **(link will be added soon)**. Final camera-ready versions of accepted papers will be given an additional page to address reviewer comments.

------

## Make a submission

Papers should describe original unpublished work or work-in-progress. Every paper will be reviewed by at least 2 members of the program committee. As reviewing will be blind, please ensure that papers are anonymous. Self-references that reveal the author's identity, e.g., "We previously showed (Smith, 1991) ...", should be avoided. Instead, use citations such as "Smith previously showed (Smith, 1991) ...". Submissions will be judged on appropriateness, clarity, originality/innovativeness, correctness/soundness, meaningful comparison, significance and impact of ideas or results.

All accepted papers will be collected into a proceedings volume to be submitted for publication in the EACL volume.

------

## Deadlines
* October 20, 2023: First call for workshop papers 
* November 15, 2023: Second call for workshop papers
* December 11, 2023: Third call for workshop papers 
* December 18, 2023: Workshop paper due 
<!-- * January 17, 2024: Direct Submission deadline (pre-reviewed ARR & main conference) -->
* January 20, 2024: Notification of acceptance 
* January 30, 2024: Camera-ready papers due 
<!-- * February 7, 2024: Proceedings due -->
* March 21 or 22, 2024: Workshop date 

------

## Invited speakers (coming soon)

<!--
**Daniel E. Ho** is the William Benjamin Scott and Luna M. Scott Professor of Law at Stanford Law School, Professor of Political Science, Senior Fellow at the Stanford Institute for Economic Policy Research, Associate Director of the Stanford Institute for Human-Centered Artificial Intelligence, and Director of the Regulation, Evaluation, and Governance Lab (RegLab). Ho2 serves on the National Artificial Intelligence Advisory Commission (NAIAC), advising the White House on AI policy, as Senior Advisor on Responsible AI at the U.S. Department of Labor, on the Committee on National Statistics (CNSTAT) of the National Academies of Science, Engineering, and Medicine, and as a Public Member of the Administrative Conference of the United States (ACUS). He has recent interest in privacy and biases in datasets used for training AI algorithms (King et al., 2023), which addresses important questions for pseudonymization.
-->

<!--
**Ildikó Pilán** has a PhD in computational linguistics and is a Senior Research Scientist from the Norwegian Computing Center, Norway. Her most impactful research comes from linguistic complexity studies within the domain of language learning, and recently from the area of anonymization and pseudonymization where she has been actively working on preparing datasets, benchmarks and models for automatic anonymization and pseudonymization of Norwegian and English data in the project Cleanup3 (e.g. Lison et al., 2021; Pilán et al., 2022). The fields her expertise is immediately concerned with are Natural Language Processing, Machine Learning, privacy protection, data privacy, Intelligent Computer-Assisted Language Learning.
-->

------

## Program committee (coming soon)
<!--
* Ahrenberg Lars, Linköping university, Sweden (NLP, NER)
* Ainiala Terhi, University of Helsinki, Finland (Finnish, onomastics)
* Aldrin Emilia, Halmstad university, Sweden (Swedish linguistics, onomastics)
* Arhar Holdt Špela, University of Ljubljana, Slovenia (digital language infrastructure)
* Dalianis Hercules, Stockholm university, Sweden (NLP, pseudonymization)
* Dobnik Simon, University of Gothenburg, Sweden (language modeling, ethics in LLMs)
* Fort Karën, Sorbonne University, France (NLP, language resources, ethics in NLP)
* Grouin Cyril, LIMSI, CNRS, Université Paris-Saclay, France (NLP, data privacy)
* Habernal Ivan, Technical University of Darmstadt, Germany (NLP, data privacy)
* Hildén Raili, University of Helsinki, Finland (Language assessment, language education)
* Kosem Iztok, University of Ljubljana, Slovenia (language resources, digital infrastructure)
* Lindström Tiedemann Therese, University of Helsinki, Finland (Scandinavian, general & applied linguistics, learner corpus research)
* Lison Pierre, Norwegian Computing Center, Norway (NLP, anonymization, LLMs)
* Megyesi Beáta, Stockholm University, Sweden (NLP, pseudonymization)
* Olsen Sussi, CST, University of Copenhagen, Denmark (NLP, language resources)
* Øvrelid Lilja, University of Oslo, Sweden (NLP, anonymization, language modeling)
* Papadopoulou Anthi, Norwegian Computing Center, Norway (NLP, anonymization, LLMs)
* Pilán Ildikó, Norwegian Computing Center, Norway (NLP, anonymization, LLMs)
* de Smedt Koenraad, University of Bergen, Norway (NLP, language resources)
* Tiedemann Jörg, University of Helsinki, Finland (NLP, language modeling, data privacy)
* Velupillai Sumithra, King’s College, London, UK (NLP, language modeling, data privacy)
* Volodina Elena, University of Gothenburg, Sweden (NLP, language resources, pseudonymization, learner corpus research)
* Vu Xuan-Son, Umeå University, Sweden (NLP, language modeling, data privacy)
-->

------

## Organizers
* [Elena Volodina](https://spraakbanken.gu.se/en/about/staff/elena), University of Gothenburg, Sweden
* [Therese Lindström Tiedemann](https://researchportal.helsinki.fi/en/persons/therese-lindstr%C3%B6m-tiedemann), University of Helsinki, Finland
* [Simon Dobnik](https://www.gu.se/en/about/find-staff/simondobnik), University of Gothenburg, Sweden
* [Xuan-Son Vu](https://people.cs.umu.se/sonvx/), Umeå university, Sweden

------

## Acknowledgments
The workshop is organized within the project [Grandma Karl is 27 years old](https://mormor-karl.github.io/) and is supported by a research grant on pseudonymization from the [Swedish Research Council](https://www.vr.se/english/swecris.html#/project/2022-02311_VR).
