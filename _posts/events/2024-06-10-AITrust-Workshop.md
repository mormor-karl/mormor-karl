---
title: "Privacy and AI: Towards a Trustworthy Ecosystem (AITrust)"
excerpt_separator: "<!--more-->"
categories:
  - events
tags:
  - outreach
  - blog
---


# AITrust workshop at [WASP-HS 2024](https://wasp-hs.org/event/ai-for-humanity-and-society-2024/)

_a cross-disciplinary forum for advancing the designing, developing and deploying of reliable and trustworthy AI applications._

## Dates and venue

### Important dates
* Aug 23, 2024: First call for workshop one-page abstracts
* September 6, 2024: One-page abstract submission deadline
* September 12, 2024: Accepted abstract notification
* September 15, 2024: Participant submissions
* November 19, 2024: Event day (9:00 - 12:00)

### Venue
* Exact address of workshop place: University of Gothenburg, Gothenburg, Sweden. Hus Patricia. Forskningsgången 6.

# Registration
(Updated on Sep 14, 2024)
Please register for our workshop, 'Privacy and AI: Towards a Trustworthy Ecosystem,' using form [1], and for the main event using form [2].

* [1] [Registration form of AITrust workshop](https://forms.gle/GGG2a3rBa1YMjJZH7)
* [2] [Registration form of the main WASP-HS 2024 Event](https://wasp-hs.org/event/ai-for-humanity-and-society-2024/)

* **The Zoom Webinar link** to join the event can be found [here](https://gu-se.zoom.us/j/65062336597).

# Program
| Order | Title | Authors | Time Frame | Chair |
|-------|--------|----------|------------|--------|
| 1     | Workshop Registration | | 08:15 - 09:00 | |
| 2     | Opening Remarks | | 09:00 - 09:05 | Sonny Vu |
| 3     | Invited Speaker 1: Dr. Krister Lindén, Research Director, Department of Digital Humanities | | 09:05 - 09:35 | Chair: Elena Volodina  |
| 4     | Responsible design of financial robo-advisors - a multidisciplinary approach | Esteban Guerrero, Gökhan Buturak, Panu Kalmi | 09:35 - 10:00 | Session 1: Applications <br> Session Chair: Simon Dobnik |
| 5     | An Extensible Framework for Real-Time Conversational Avatars | Somayeh Jafaritazehjani, Khanh-Tung Tran, Xuan-Son Vu, Johanna Björklund | | |
| 6     | Transformer-assisted Hate Crime Classification and Estimation in Sweden | Hollis Sargeant, Hannes Waldetoft, Måns Magnusson | | |
| 7     | Trustworthy AI in the public sector: Insights and recommendations grounded in a case study | Alexander Berman, Karl de Fine Licht, Vanja Carlsson | | |
|       | **COFFEE BREAK** | | 10:00 - 10:20 | |
| 8     | AI for open research data with Grandma Karl | Maria Irena Szawerna, Simon Dobnik, Therese Lindström Tiedemann, Lisa Södergård, Ricardo Muñoz Sánchez, Xuan-Son Vu, Elena Volodina | 10:20 - 10:50 | Session 2: Theoretical / CoreNLP <br> Session Chair: Lili Jiang |
| 9     | Intersectional Hallucinations in Structured Synthetic Data | Ericka Johnson, Saghi Hajisharif | | |
| 10    | Mitigate Unfairness in Adversarial Robustness of Deep Neural Networks | Seyedhamidreza Mousavi, Seyedali Mousavi, Masoud Daneshtalab | | |
| 11    | Trustworthy AI and Misplaced Trust Ethical Implications from the Philosophy and Moral Psychology of Trust | Dorna Behdadi | 10:50 - 11:20 | Session 3: Theory + Linguistics <br> Session Chair: Therese Lindström Tiedemann |
| 12    | AI's truth is not my truth and what language has to do with it | Martina Wiltschko & Preeti Kumari | | |
| 13    | Explainability of Artificial Intelligence Systems: Mapping the Academic Discourse | Signe Skov | | |
| 14    | Invited Speaker 2: Prof. Virginia Dignum, Umeå University and a member of the United Nation's AI Body | | 11:20 - 11:50 | Chair: Lili Jiang |
| 15    | Closing Remarks | | 11:50 - 12:00 | Sonny Vu |

[Back to top](#dates-and-venue)


## Call for one-page abstracts
The wider adoption of machine learning (ML) and artificial intelligence (AI) make several applications successful across societies such as healthcare, finance, robotics, transportation and industry operations, by inducing intelligence in real-time. It is desirable to design and develop reliable and trustworthy AI applications that offer trustworthy services to users, especially in high-stakes decision making. For instance, AI-assisted robotic surgery, automated financial trading, autonomous driving and many more modern applications are vulnerable to reidentification attacks, concept drifts, dataset shifts, misspecifications, misconfiguration of AI algorithms, perturbations, and adversarial attacks beyond human or even machine comprehension level, thereby posing dangerous threats to various stakeholders at different levels. Moreover, building trustworthy AI systems requires intense  multi-party efforts in addressing different mechanisms and approaches that could enhance user and public trust. To name a few, the following topics are of interest in trustworthy AI: (i) privacy preservation, (ii) bias and fairness, (iii) robust mitigation of adversarial attacks, (iv) improved privacy and security in model building, (v) ethical AI, (vi) model attribution and (vii) scalability of models under adversarial settings. All of these topics are important and need to be addressed. 

This workshop  covers new results and on-going work in AI to address challenges for ensuring reliability in trustworthy systems. The challenges in different AI systems include, , but are not limited to (i) data collection and use, (ii) data sharing and aggregation, (iii) re-identification, and (iv) secure and private learning. Nonetheless, all aspects of AI systems that can deal with reliable, robust and secure issues are within the scope of this workshop. It will focus on robustness and performance guarantees, as well as consistency, transparency and safety of AI which are vital to ensure reliability. The workshop brings together experts from academics and industries and inspires discussion on  building trustworthy AI systems including developing and assessing theoretical and empirical methods, practical applications, initializing  new ideas and identifying directions for future studies. Original contributions, on-going work, as well as comparative studies among different methods, are all welcome.

Participants are encouraged to submit a one-page abstract about the research work that they will present at the workshop. Depending on the number of submissions and topics of interest, we will arrange short talks to present  selected works. All authors of accepted abstracts should prepare a poster to present at the workshop to foster discussions among participants, regardless of whether the papers are selected for short talks.

Topics of the workshop include, but are not limited to:

* Robustness of machine learning/deep learning/reinforcement learning algorithms and trustworthy systems in general.
* Confidence, consistency, and uncertainty in model predictions for reliability beyond robustness.
* Transparent AI concepts in data collection, model development, deployment and explainability.
* Adversarial attacks - evasion, poisoning, extraction, inference, and hybrid.
* New solutions to make a system robust and secure to novel or potentially
adversarial inputs; to handle model misspecification, corrupted training data, addressing concept drifts, dataset shifts, and missing/manipulated data instances.
* Theoretical and empirical analysis of reliable/robust/secure ML methods.
* Comparative studies with competing methods without reliable/robust certified
properties.
* Applications of reliable/robust machine learning algorithms in domains such as
healthcare, biomedical, finance, computer vision, natural language processing (LLMs/LVMs),
big data, and all other relevant areas.
* Unique societal and legal challenges facing reliability for trustworthy AI systems.
* Secure learning from data having high missing values, incompleteness, noisy
* Private learning from sensitive and protected data

**Submission Information**
- Suggested Template: [https://www.overleaf.com/latex/templates/acl-2023-proceedings-template/qjdgcrdwcnwp](https://www.overleaf.com/latex/templates/acl-2023-proceedings-template/qjdgcrdwcnwp) (MS Word or other similar tools are also acceptable).
- Submission Page (Google Form): [https://forms.gle/cfgKqjV71M6Y6naMA](https://forms.gle/cfgKqjV71M6Y6naMA)
- Page limit: 1 page for main abstract with unlimited additional pages for references.
- Note: anonymity is not required for the abstract submission.

<!--  
Internal deadlines (TBA):
* June 21, 2024: First call for workshop one-page abstracts
* September 1, 2024: One-page abstracts submission deadline
* September 10, 2024: Accepted abstracts notification
* September 15, 2024: Participant submissions
* November 19, 2024: Event day
-->


## Program committee 

* Elena Volodina, University of Gothenburg, Sweden
* Johanna Björklund, Umeå university, Sweden
* Simon Dobnik, University of Gothenburg, Sweden
* Lili Jiang, Umeå university, Sweden
* Xuan-Son Vu, Umeå university and DeepTensor AB, Sweden
* Therese Lindström Tiedemann, University of Helsinki, Finland
* Ricardo Muñoz Sánchez, University of Gothenburg, Sweden
* Maria Irena Szawerna, University of Gothenburg, Sweden
* Lisa, Södergård, University of Helsinki, Finland

[Back to top](#dates-and-venue)


## Organizers

|  |
|--|
|**General chair**|
|* [Xuan-Son Vu](https://people.cs.umu.se/sonvx/), Umeå university and DeepTensor AB, Sweden|
|**General co-chairs**|
|* [Lili Jiang](https://people.cs.umu.se/lili.jiang/), Umeå university, Sweden<br>* [Elena Volodina](https://spraakbanken.gu.se/en/about/staff/elena), University of Gothenburg, Sweden <br>* [Simon Dobnik](https://www.gu.se/en/about/find-staff/simondobnik), University of Gothenburg, Sweden <br> * [Therese Lindström Tiedemann](https://researchportal.helsinki.fi/en/persons/therese-lindstr%C3%B6m-tiedemann), University of Helsinki, Finland <br>* [Johanna Björklund](https://www.umu.se/personal/johanna-bjorklund/), Umeå university, Sweden|
|**Organizing co-chairs**|
|* [Ricardo Muñoz Sánchez](https://rimusa.github.io/), University of Gothenburg, Sweden <br>* [Maria Irena Szawerna](https://spraakbanken.gu.se/en/about/staff/maria-szawerna), University of Gothenburg, Sweden <br>* [Lisa Södergård](https://researchportal.helsinki.fi/en/persons/greta-lisa-s%C3%B6derg%C3%A5rd) University of Helsinki, Finland. <!-- <br>-->|
|**Contact** mormor.karl@svenska.gu.se or aitrust-research@googlegroups.com|

| Anti-harassment policy |
|--|
| AITrust workshop adheres to the ACL’s anti-harassment policy [https://www.aclweb.org/adminwiki/index.php?title=Anti-Harassment_Policy](https://www.aclweb.org/adminwiki/index.php?title=Anti-Harassment_Policy). |

| Acknowledgments |
|--|
|The workshop is organized within the research environment project [Grandma Karl is 27 years old](https://mormor-karl.github.io/), WASP Media & Language, and STINT Projects.|
